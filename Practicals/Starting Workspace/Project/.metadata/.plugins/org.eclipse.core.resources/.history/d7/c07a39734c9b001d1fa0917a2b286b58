//Lesson 24
package com.virtualpairprogrammers;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import scala.Tuple2; 

public class Lesson24 {

	public static void main(String[] args) {
		
//Lesson 24 Continued worked solution with sorting
/* So far we have an RDD containing what we think are interesting words. Now we just have to count them. THis is just like what we did in the previous chapter. Build a pair of RDD
 * Keys are the words, values are the value of one. Then we reduce on that pair RDD where we sum up values by reducing the key
 * key    | value
 * docker | 1
 * 
 */
		
		System.setProperty("hadoop.home.dir", "c:/hadoop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN); 
		
		SparkConf conf = new SparkConf().setAppName("startingSpark").setMaster("local[*]"); 
		JavaSparkContext sc = new JavaSparkContext(conf);

		JavaRDD<String> initialRdd = sc.textFile("src/main/resources/subtitles/input.txt");
		
		JavaRDD<String> lettersOnlyRdd = initialRdd.map( sentence -> sentence.replaceAll(" ^[a-zA-Z\\s] ", "").toLowerCase()); 
		
		JavaRDD<String> removedBlankLines = lettersOnlyRdd.filter( sentence -> sentence.trim().length() > 0); 

		JavaRDD<String> justWords = removedBlankLines.flatMap( sentence -> Arrays.asList(sentence.split(" ")).iterator());

		JavaRDD<String> justInterestingWords = justWords.filter( word -> Util.isNotBoring(word));


		
/*lets start here. What we want to do is call map to pair we want the elements to map to the java tuple 2. We will have one string and the other value is a long
 * the word is the key and the number 1 as a long will be the value. This will be saved to a JavaPairRDD with string as key and long as value. Make sure to import java pair RDD if needed
 * Maybe you will have a compiler error below. If so, the problem is type mismatch cant convert java pair rdd object, object, to pair rdd string, long. 
 * This happens because we simply have to import Tuple 2. So the compiler doesnt know what types need to be here its as simple as importing.
 */		
		JavaPairRDD<String, Long> pairRdd = justInterestingWords.mapToPair( word -> new Tuple2<String, Long>(word, 1L));

/* Now we will have an error because the Tuple business gets a little sticky. Change list type to Tuple2<String, Long>>
 * When we do the print ln we can assume there will be good string implementation for the totals.
 * OUTPUT:
 * (deployments, 1)
 * ...
 * Okay this is great. Only one instance of a blank. Now let us run a reduced by key to add up all of those ones. 
 */
		JavaPairRDD<String, Long> totals = pairRdd.reduceByKey((value1, value2) -> value1 + value2);
		
/*OUTPUT:
 * (tomcat, 93)
 * (randomly, 5)
 * (everythings, 3)
 * ...
 * A lot of low counts will NOT be a part of the big results. 
 */
		
//		List<Tuple2<String, Long>> results = pairRdd.take(50);
		List<Tuple2<String, Long>> results = totals.take(50);

		results.forEach(System.out::println);
				
		sc.close();
	}

}
