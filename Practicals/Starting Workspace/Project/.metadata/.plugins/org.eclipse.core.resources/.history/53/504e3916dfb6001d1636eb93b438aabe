package com.virtualpairprogrammers;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class Lesson109 {

/* Lesson 109 Case Study Walkthrough.
 * 
 * First thing to do is copy the data into resources folder. Instructor makes new class called VPPChapterViews. We can copy and paste some part of the housePriceFields java file.
 */
	
	public static void main(String[] args) { //boilerplate
		
		System.setProperty("hadoop.home.dir", "c:/hadooop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN);
		
		SparkSession spark = SparkSession.builder()
				.appName("Gym Competitors")
				.config("spark.sql.warehouse.dir", "file:///c:/tmp/")
				.master("local[*]")
				.getOrCreate();
		
		Dataset<Row> csvData = spark.read()
				.option("header",  true)
				.option("inferSchema", true)
				.csv("src/main/resources/vppChapterViews.part-r-00000.csv"); //for now taking one of the csvs 
	}
}