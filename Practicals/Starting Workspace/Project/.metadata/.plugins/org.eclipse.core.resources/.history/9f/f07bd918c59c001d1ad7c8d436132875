//Lesson 28
package com.virtualpairprogrammers;

import java.util.Arrays;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import scala.Tuple2;

public class Lesson28 {
	
	public static void main(String[] args) {

	
		//Lesson 28-32 AWS EMR optional section, will document some steps
/* Lesson 28 How to start EMR Spark Cluster
 * We will be running our Spark app on a real hardware cluster using Amazon EMR. Will be documenting how to do this. Assuming account for AWS already created and familiarity with AWS.
 * Even if you dont have an account, this will be good for insight. Everything done in the chapter will incur cost. If failed to delete or terminate resources you will be billed!
 * 
 */
	
		System.setProperty("hadoop.home.dir", "c:/hadoop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN); 
		
		SparkConf conf = new SparkConf().setAppName("startingSpark").setMaster("local[*]"); 
		JavaSparkContext sc = new JavaSparkContext(conf);
	
	
		sc.close();
	
	}

}
