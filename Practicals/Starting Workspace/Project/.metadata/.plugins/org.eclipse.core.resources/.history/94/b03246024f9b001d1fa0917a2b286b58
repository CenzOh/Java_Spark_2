package com.virtualpairprogrammers;

import java.util.Arrays;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import scala.Tuple2;

public class Lesson25 {
	
	public static void main(String[] args) {

	
		//Lesson 25 why do sorts not work with foreach?
/* We will address the common misconception with the sort transformation that we used in the previous chapter. We will look at the Coalesce function. 
 * Last time we built the solution which processes a (relatively) big data file. Real life can be arbitrarily big. Processes and lists top 10 important keywords. Reads the subtitles of the course
 * We avoided the common trap with the sort routine. Many people new to spark fall into the trap. Lets address it!
 * 
 * What are we talking about? Lets recap, we did a lot of transformations and ended with a sorting transformation and finish by taking first ten results of RDD. 
 * Because we already did so, that will take the ten most popular key words. HOWEVER we did NOT have to do a take!! Quite common to do a foreach
 */
	
		System.setProperty("hadoop.home.dir", "c:/hadoop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN); 
		
		SparkConf conf = new SparkConf().setAppName("startingSpark").setMaster("local[*]"); 
		JavaSparkContext sc = new JavaSparkContext(conf);
	
		JavaRDD<String> initialRdd = sc.textFile("src/main/resources/subtitles/input.txt");	
		
		JavaRDD<String> lettersOnlyRdd = initialRdd.map( sentence -> sentence.replaceAll(" ^[a-zA-Z\\s] ", "").toLowerCase()); 
		
		JavaRDD<String> removedBlankLines = lettersOnlyRdd.filter( sentence -> sentence.trim().length() > 0); 
	
		JavaRDD<String> justWords = removedBlankLines.flatMap( sentence -> Arrays.asList(sentence.split(" ")).iterator());
		
		JavaRDD<String> blankWordsRemoved = justWords.filter(word -> word.trim().length() > 0);
	
		JavaRDD<String> justInterestingWords = blankWordsRemoved.filter( word -> Util.isNotBoring(word));
		
		JavaPairRDD<String, Long> pairRdd = justInterestingWords.mapToPair( word -> new Tuple2<String, Long>(word, 1L));
	
		JavaPairRDD<String, Long> totals = pairRdd.reduceByKey((value1, value2) -> value1 + value2);

		JavaPairRDD<Long, String> switched = totals.mapToPair(tuple -> new Tuple2<Long, String> (tuple._2, tuple._1 ));

		JavaPairRDD<Long, String> sorted = switched.sortByKey(false);

//Lets look at the RDD after doing the sort
		
//		List<Tuple2<Long, String>> results = sorted.take(50);
//		results.forEach(System.out::println);
				
		sc.close();
	
	}

}
