package com.virtualpairprogrammers;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.ml.feature.OneHotEncoderEstimator;
import org.apache.spark.ml.feature.StringIndexer;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.ml.regression.LinearRegression;
import org.apache.spark.ml.regression.LinearRegressionModel;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class Lesson106 {

/* Lesson 106 Understanding Vectors
 * 
 */
	
	public static void main(String[] args) {
		
		System.setProperty("hadoop.home.dir", "c:/hadooop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN);
		
		SparkSession spark = SparkSession.builder()
				.appName("Gym Competitors")
				.config("spark.sql.warehouse.dir", "file:///c:/tmp/")
				.master("local[*]")
				.getOrCreate();
		
		Dataset<Row> csvData = spark.read()
				.option("header",  true)
				.option("inferSchema", true)
				.csv("src/main/resources/GymCompetition.csv");
		
//		csvData.printSchema(); //to review the schema again
		
		StringIndexer genderIndexer = new StringIndexer(); 
		genderIndexer.setInputCol("Gender"); 
		genderIndexer.setOutputCol("GenderIndex");
		csvData = genderIndexer.fit(csvData).transform(csvData);
		
		csvData.show();
		
/* CompetitorID | Gender | Age | Height | Weight | NoOfReps | GenderIndex
 * 1			| M	  	 | 23  | 180    | 88	 | 55       | 0.0
 * 4            | F      | 24  | 166    | 60     | 44       | 1.0
 */
		
		OneHotEncoderEstimator genderEncoder = new OneHotEncoderEstimator();
		genderEncoder.setInputCols(new String[] {"GenderIndex"});
		genderEncoder.setOutputCols(new String[] {"GenderVector"});
		csvData = genderEncoder.fit(csvData).transform(csvData);
		csvData.show();
		
/* CompetitorID | Gender | Age | Height | Weight | NoOfReps | GenderIndex | GenderVector
 * 1			| M	  	 | 23  | 180    | 88	 | 55       | 0.0         | (1,[0],[1,0])
 * 4            | F      | 24  | 166    | 60     | 44       | 1.0         | (1,[],[])
 * 
 * Remember we first mentioned vectors they are a bit like arrays. We can see the vector vs array. The spark designers COULD have chosen arrays but there is an issue.
 * Imagine working with a category with 20 different values. That array would have a size of 19. Most of the values would be 0. Now think we have 20k records of this example with huge
 * arrays almost all of which are 0s would take up so much memory. So isntead, the vector ia neater and memory efficient way to represent an array. Lets understand how to read the vector.
 * 
 * So lets keep the example simple, we have a feature with 5 possible values. Heres what it would look like:
 * 
 * Grade | Array     | Vector
 * A     | [0,0,0,0] | (4,[],[])
 * A     | [0,0,0,0] | (4,[],[])
 * A     | [0,0,0,0] | (4,[],[])
 * A     | [0,0,0,0] | (4,[],[])
 * A     | [0,0,0,0] | (4,[],[])

 */
		
		VectorAssembler vectorAssembler = new VectorAssembler();
		vectorAssembler.setInputCols(new String[] {"Age", "Height", "Weight"} );		
		vectorAssembler.setOutputCol("features");
		Dataset<Row> csvDataWithFeatures = vectorAssembler.transform(csvData);
		
//		csvDataWithFeatures.show();
		
		Dataset<Row> modelInputData = csvDataWithFeatures.select("NoOfReps", "features").withColumnRenamed("NoOfReps", "label");
		modelInputData.show();
		
		LinearRegression linearRegression = new LinearRegression();
		LinearRegressionModel model = linearRegression.fit(modelInputData); 
		System.out.println("The model has intercept " + model.intercept() + " and coefficients " + model.coefficients());

		model.transform(modelInputData).show();
	}
}