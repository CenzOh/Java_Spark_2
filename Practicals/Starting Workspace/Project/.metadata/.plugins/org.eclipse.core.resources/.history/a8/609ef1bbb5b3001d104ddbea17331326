package com.virtualpairprogrammers;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class Lesson97 {

public static void main(String[] args) {
		
		System.setProperty("hadoop.home.dir", "c:/hadooop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN);
		
		SparkSession spark = SparkSession.builder()
				.appName("Gym Competitors")
				.config("spark.sql.warehouse.dir", "file:///c:/tmp/")
				.master("local[*]")
				.getOrCreate();
		
		Dataset<Row> csvData = spark.read()
				.option("header",  true)
				.option("inferSchema", true)
				.csv("src/main/resources/kc_house_data.csv"); //changed
		
		csvData.printSchema();
		
		csvData.show();
		
/* This is a much bigger file with lots of columns. THe idea is the price column is our label, the value we want to predict. We have all sorts of prices. Other cols are num of bedrooms,
 * num of bathrooms. We can see the numbers are calculated in a consistent way that is what is important to see. Living space in sq feet, lot in sq ft, etc. Any of these attributes
 * can be a parameter for our linear regression. At this stage, some of the parameters WILL be good, others wont. We will not include every parameters. We will learn how to select
 * parameters later on. For now lets use 2 or 3 to build a model using them. Lets use num of bedrooms, bathrooms, and sq foot living size. 
 * 
 */
	}
}