package com.virtualpairprogrammers;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class Lesson102 {

/* Lesson 102 Correlation Features
 * 
 * Idea of correlation is, we ask Spark what is correlation between sqft living (living space) and value we are trying to predict. Spakr gives us a number between -1 and 1.
 * 0 - no correlation / no relationship
 * 1 - strong correlation
 * -1 - strong correlation
 * 
 * 1 means size of property increase, price increase. -1 means size of property increases, price DECREASES. A feature with a strong correlation is a good parameter for our model.
 * Feature with no correlation / close to 0 not good in our model. Lets find out what correlations are for each input variable. Do this with .stat() method
 */
	
	public static void main(String[] args) {
		
		System.setProperty("hadoop.home.dir", "c:/hadooop"); 
		Logger.getLogger("org.apache").setLevel(Level.WARN);
		
		SparkSession spark = SparkSession.builder()
				.appName("Gym Competitors")
				.config("spark.sql.warehouse.dir", "file:///c:/tmp/")
				.master("local[*]")
				.getOrCreate();
		
		Dataset<Row> csvData = spark.read()
				.option("header",  true)
				.option("inferSchema", true)
				.csv("src/main/resources/kc_house_data.csv"); 

		csvData.describe().show();
	}
}