package com.virtualpairprogrammers;

import java.util.ArrayList;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.RowFactory;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.Metadata;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;


public class Lesson67 {
	
/* Lesson 67 Ordering
 * Last time, we made a report of all the ERRORs, FATALs, etc from the big log txt. Its all output in a random order so lets fix that. One option is to add the order by to the main SQL
 * as seen before. After doing group can do order by.
 */
	
	@SuppressWarnings("resource") 
	public static void main(String[] args) {
		System.setProperty("hadoop.home.dir", "c:/hadoop");
		Logger.getLogger("org.apache").setLevel(Level.WARN);
	
		SparkSession spark = SparkSession.builder().appName("testingSql").master("local[*]")
				.config("spark.sql.warehouse.dir", "file:///c:/tmp/")
				.getOrCreate();
				
		Dataset<Row> big_dataset = spark.read().option("header", true).csv("Src/main/resources/bigLog.txt");
		
		big_dataset.createOrReplaceTempView("logging_table");	
		
//		Dataset<Row> results = spark.sql("select level, date_format(datetime, 'MMMM') as month, count(1) as total from logging_table group by level, month order by month"); //one option

/* The problem with this: Results does not have natural order, its alpha order by month. April, August, December, etc
 * How to handle? Many ways to do this. One thing is to add a column which is numerical month starting with 1 run to 12. Order by that column instead.
 */
//		Dataset<Row> results = spark.sql
//				("select level, date_format(datetime, 'MMMM') as month, date_format(datetime, 'M') as monthnum, count(1) as total "
//						+ "from logging_table group by level, month order by monthnum"); //added month num col so we can have numerical version.
		
/* THERE WAS A CRASH. Why was that? Error message says `datetime is neither present in group by nor is it an aggregate function...` 
 * There is a fault adding the additional column, we are grouping by level and month so there are two rows where the level and month are identical. What about monthnum? 
 * If it did execute we would get results like this: 
 * 
 * Level | Month | Count(1) | Monthnum
 * WARN | December | 2 | [12, 12]
 * 
 * We dont want this^^ so we must group by the monthnum as well. If we dont care which value we get (which we dont) just wrap the month num with first() function
 */

		Dataset<Row> results = spark.sql
				("select level, date_format(datetime, 'MMMM') as month, first(date_format(datetime, 'M')) as monthnum, count(1) as total "
						+ "from logging_table group by level, month order by monthnum"); //added first() fcn for month num
		
/* It prints and in weird order January, October, November, February, etc. Does an alphabetical sort
 */
		
		results.show(100); 
		
		spark.close();
	
	}
}
