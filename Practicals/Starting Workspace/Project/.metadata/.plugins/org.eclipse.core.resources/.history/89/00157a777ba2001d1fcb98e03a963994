package com.virtualpairprogrammers;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;

public class Lesson57 {
	
/* Lesson 57 SparkSQL getting started
 * We have been previously working on various experiments in Main.java. For this section we will modify the code in that section (I will still put code in different java files)
 * for easier readibility. There is another starting workspace with up to date code in case we skipped the first section and jumped straight into this section. 
 * In section 1, one of the joys of working with spark is that there are not a lot of dependencies that we need / no need for specific software. We simply have a meavn pom.xml file
 * and we can see in there the dependencies are basic, spark core, spark SQL (we added previously for this part of the course), and apache hadoop (access HDFS file system).
 */
	
	@SuppressWarnings("resource") //boiler plate start
	public static void main(String[] args) {
		System.setProperty("hadoop.home.dir", "c:/hadoop");
		Logger.getLogger("org.apache").setLevel(Level.WARN);
	
	
//		SparkConf conf = new SparkCOnf().setAppName("startingSpark").setMaster("local[*]");
//		JavaSparkContext sc = new JavaSparkContext(conf);
	}
}
